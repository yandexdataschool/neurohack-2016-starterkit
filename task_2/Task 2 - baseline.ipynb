{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import chain\n",
    "from scipy import io\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.linalg import eig\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import h5py\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"train.h5\"\n",
    "TEST_FILE = \"test.h5\"\n",
    "SAMPLING_RATE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHANNEL_NAMES = np.array(['T5', 'T3', 'F7', 'F3', 'C3', 'P3', 'Fp1', 'Fpz', 'A1', 'O1', 'Cz', 'Oz', 'Fz', 'Pz', 'O2', 'A2', 'Fp2', 'P4', 'C4', 'F4', 'F8', 'T4', 'T6', 'AUX'])\n",
    "CHANNELS_TO_DISCARD = ['A1', 'A2', 'AUX']\n",
    "EYE_CHANNEL = \"Fp1\"\n",
    "CSP_FREQUENCES = [(6,10),(8,12),(10,14),(12,16),(14,18),(16,20),(18,22),(20,24),\n",
    "                     (22,26),(24,28),(26,30),(28,32),(30,34),(32,36),(34,38)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, sampling_rate, order=5):\n",
    "    \"\"\"\n",
    "    For a given order (5 by default), computes numerator (b)\n",
    "    and denominator (a) polynomials\n",
    "    of the IIR filter (bandpass between lowcut and highcut).\n",
    "    \"\"\"\n",
    "    nyq_freq = sampling_rate*0.5\n",
    "    low = lowcut/nyq_freq\n",
    "    high = highcut/nyq_freq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_high_low_pass(lowcut, highcut, sampling_rate, order=5):\n",
    "    \"\"\"\n",
    "    For a given order (5 by default), computes numerator (b_high, b_low)\n",
    "    and denominator (a_high, a_low) polynomials of the IIR filters\n",
    "    (highpass for lowcut, lowpass for highcut).\n",
    "    \"\"\"\n",
    "    nyq_freq = sampling_rate*0.5\n",
    "    lower_bound = lowcut/nyq_freq\n",
    "    higher_bound = highcut/nyq_freq\n",
    "    b_high, a_high = butter(order, lower_bound, btype='high')\n",
    "    b_low, a_low = butter(order, higher_bound, btype='low')\n",
    "    return b_high, a_high, b_low, a_low\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, sampling_rate, order=5, how_to_filt = 'separately'):\n",
    "    \"\"\"\n",
    "    Applies Butterworth bandpass filter (with a given order, 5 by default) to the data.\n",
    "    If how_to_filt = 'separately', applies highpass than lowpass, and thus results\n",
    "        in bandpass between lowcut and highcut.\n",
    "    If how_to_filt == 'simultaneously', applies bandpass directly.\n",
    "    \"\"\"\n",
    "    if how_to_filt == 'separately':\n",
    "        b_high, a_high, b_low, a_low = butter_high_low_pass(lowcut, highcut, sampling_rate, order=order)\n",
    "        y = lfilter(b_high, a_high, data)\n",
    "        y = lfilter(b_low, a_low, y)\n",
    "    elif how_to_filt == 'simultaneously':\n",
    "        b, a = butter_bandpass(lowcut, highcut, sampling_rate, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, iter_numb):\n",
    "    \"\"\"\n",
    "    Repetitively (specified by iter_numb) applies outliers removal to the data:\n",
    "    deletes samples which power deviates more than 2.5 SDs from the mean.\n",
    "    \"\"\"\n",
    "    data_pwr = np.sqrt(np.sum(data**2, 0))\n",
    "    mask = np.ones(data.shape[1], dtype=np.bool)\n",
    "    for i in range(iter_numb):\n",
    "        X_mean = np.mean(data_pwr[mask])\n",
    "        X_std = np.std(data_pwr[mask])\n",
    "        mask &= np.abs(data_pwr - X_mean) < 2.5*np.abs(X_std)\n",
    "        print('Samples left after outliers removal: %d' % mask.sum())\n",
    "    return mask\n",
    "\n",
    "def remove_eog_simple(data, eyechan, number_artefact_components=3):\n",
    "    \"\"\"\n",
    "    Blinks and eye artefacts removal by singular value decomposition.\n",
    "    \n",
    "    Arguments:\n",
    "    data: EEG data, numpy array [n_channels, n_samples]\n",
    "    eyechan: channel nummer used for artefacts detection\n",
    "    number_artefact_components: number of eigenvalues used - the number\n",
    "       of components the artefacts are presumed to have\n",
    "       \n",
    "    Returns artefact-free EEG time series and the matrix of corresponding transformation\n",
    "    \"\"\"\n",
    "    only_eye_chan = data[eyechan, :]\n",
    "    exceed_mask = only_eye_chan > 3*np.mean(np.absolute(only_eye_chan))\n",
    "    print('Number of samples identified as containing eye artefacts: %d' % np.sum(exceed_mask))\n",
    "    U, S, V = np.linalg.svd(data[:, exceed_mask[0,:]], full_matrices=True)\n",
    "    M_eog = np.eye(U.shape[0])-np.dot(U[:,0:number_artefact_components],U[:,0:number_artefact_components].T)\n",
    "    \n",
    "    return np.dot(M_eog, data), M_eog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outer_n(n):\n",
    "    return np.array(list(range(n))+list(range(-n,0)))\n",
    "\n",
    "def whitener(C, rtol=1e-15):\n",
    "    e, E = np.linalg.eigh(C)\n",
    "    return reduce(np.dot, [E, np.diag(np.where(e > np.max(e) * rtol, e, np.inf)**-0.5), E.T])\n",
    "\n",
    "def csp_base(C_a, C_b):\n",
    "    P = whitener(C_a + C_b)\n",
    "    P_C_b = reduce(np.dot, [P, C_b, P.T])\n",
    "    _, _, B = np.linalg.svd((P_C_b))\n",
    "    return np.dot(B, P.T)\n",
    "\n",
    "def csp(C_a, C_b, m):\n",
    "    W = csp_base(C_a, C_b)\n",
    "    assert W.shape[1] >= 2*m\n",
    "    return W[outer_n(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_CSP_matr(data, states_labels, main_state, N_comp, other_state=None, mode='one_vs_all'):\n",
    "    \"\"\"\n",
    "    Computes matrix of CSP (common spatial pattern) transform which maximizes the signal\n",
    "    variance for one condition while minimizing the variance for the other condition.\n",
    "    CSP method is based on the simultaneous diagonalization of the covariance matrices of both conditions.\n",
    "    main_state is the label of a state for which variance will be maximized.\n",
    "    if mode == 'one_vs_all', then the variance is minimized for all states other than main_state.\n",
    "    if mode == 'pairwise', then the variance is minimized for a specified state (other_state).\n",
    "    Returns matrix of eigenvectors corresponding to N_comp highest eigenvalues and\n",
    "    N_comp lowest  eigenvalues.\n",
    "    \"\"\"\n",
    "    A = data[:, (states_labels == main_state)[0,:]]\n",
    "    if mode == 'one_vs_all':\n",
    "        B = data[:, (states_labels != main_state)[0,:]]\n",
    "    elif mode == 'pairwise':\n",
    "        if other_state == None:\n",
    "            print(\"Other state must be specified\")\n",
    "            return None\n",
    "        else:\n",
    "            B = data[:, (states_labels == other_state)[0,:]]\n",
    "    \n",
    "    C1 = np.cov(A)\n",
    "    C2 = np.cov(B)\n",
    "    \n",
    "    return csp(C1,C2,N_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def const_features(data,states_labels,states_codes,sr,feat_type,freq_ranges,how_to_filt,N_csp_comp,win,order=5,normalize=False):\n",
    "    '''\n",
    "    Filters data according to specified bands (in freq_range) and derives CSP transformations for each band.\n",
    "    Type of CSP should be provided in feat_type: pairwise or one-vs-all (recommended).\n",
    "    Number of CSP components should be provided in N_csp_comp (for a given N, N first and N last components will be used).\n",
    "    Time interval for averaging is specified in win.\n",
    "    If normalize=True, each data point is in [0,1].\n",
    "    Returns array of transformed data, list of CSP transform matrices (in arrays), \n",
    "    and array of state codes for each of the final features (i.e., which state was first while this CSP projection was computed)\n",
    "    '''\n",
    "    final_data = np.zeros((1, data.shape[1]))\n",
    "    all_CSPs = []\n",
    "    where_states = []\n",
    "    \n",
    "    if feat_type == 'CSP_pairwise':\n",
    "        for freq in freq_ranges:\n",
    "            data_filt = butter_bandpass_filter(data, freq[0], freq[1], sr, order, how_to_filt)\n",
    "            all_states_CSP = []\n",
    "            for st in states_codes:\n",
    "                for oth_st in np.array(states_codes)[np.array(states_codes)!=st]:\n",
    "                    CSP_st = get_CSP_matr(data_filt, states_labels, st, N_csp_comp, other_state=oth_st, mode='pairwise')\n",
    "                    all_states_CSP.append(np.dot(CSP_st, data_filt))\n",
    "                    all_CSPs.append(CSP_st)\n",
    "                    where_states.extend([st]*(N_csp_comp*2))\n",
    "                data_transformed = np.vstack(all_states_CSP)**2\n",
    "            final_data = np.vstack((final_data, data_transformed))\n",
    "            \n",
    "    elif feat_type == 'CSP_one_vs_all':\n",
    "        for freq in freq_ranges:\n",
    "            data_filt = butter_bandpass_filter(data, freq[0], freq[1], sr, order, how_to_filt)\n",
    "            all_states_CSP = []\n",
    "            for st in states_codes:\n",
    "                CSP_st = get_CSP_matr(data_filt, states_labels, st, N_csp_comp, other_state=None, mode='one_vs_all')\n",
    "                all_states_CSP.append(np.dot(CSP_st, data_filt))\n",
    "                all_CSPs.append(CSP_st)\n",
    "                where_states.extend([st]*(N_csp_comp*2))\n",
    "            data_transformed = np.vstack(all_states_CSP)**2\n",
    "            final_data = np.vstack((final_data, data_transformed))\n",
    "            \n",
    "    elif feat_type == 'no_filt_no_csp':\n",
    "        final_data = np.vstack((final_data, data**2))\n",
    "\n",
    "    final_data = final_data[1:,:]\n",
    "    a_ma = 1\n",
    "    b_ma = np.ones(win)/float(win)\n",
    "    final_data = lfilter(b_ma, a_ma, final_data)\n",
    "    if normalize:\n",
    "        final_data = final_data/np.sum(final_data,0)[np.newaxis,:]\n",
    "    print('Shape of data matrix: ', final_data.shape)\n",
    "        \n",
    "    return final_data, all_CSPs, np.array(where_states)\n",
    "\n",
    "def filt_apply_CSPs(data, sr, freq_range, all_CSPs, how_to_filt, win, order=5, normalize=False, no_filt_no_csp=False):\n",
    "    '''\n",
    "    Filters data according to specified bands (in freq_range) and applies corresponding CSP transformations (in all_CSPs).\n",
    "    Order in freq_range and all_CSPs must be the same.\n",
    "    If normalize=True, each data point is in [0,1].\n",
    "    '''\n",
    "    if no_filt_no_csp == False:\n",
    "        N_csp_per_freq = len(all_CSPs) // len(freq_range)\n",
    "        all_CSPs_copy = list(all_CSPs)\n",
    "        transformed_data = np.zeros((1, data.shape[1]))\n",
    "        for fr_ind in range(len(freq_range)):\n",
    "            filt_data = butter_bandpass_filter(data,freq_range[fr_ind][0],freq_range[fr_ind][1],sr,order,how_to_filt)\n",
    "            for csp_ind in range(N_csp_per_freq):\n",
    "                transformed_data = np.vstack((transformed_data, np.dot(all_CSPs_copy.pop(0), filt_data)))\n",
    "        final_data = transformed_data[1:,:]**2\n",
    "        \n",
    "    elif no_filt_no_csp == True:\n",
    "        final_data = data**2\n",
    "        \n",
    "    a_ma = 1\n",
    "    b_ma = np.ones(win)/float(win)\n",
    "    final_data = lfilter(b_ma, a_ma, final_data)\n",
    "    if normalize:\n",
    "        final_data = final_data/np.sum(final_data,0)[np.newaxis,:]\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_eeg(eeg_data, sampling_rate, channel_names, states_codes):\n",
    "    # Prefilter eeg data\n",
    "    eeg_data = butter_bandpass_filter(eeg_data, 0.5, 45, sampling_rate, order=5, how_to_filt='separately')\n",
    "    \n",
    "    # Remove empty channels\n",
    "    # Detect constant (zero) channels\n",
    "    channels_mask = np.ones(len(channel_names), dtype=np.bool)\n",
    "    for channel in CHANNELS_TO_DISCARD:\n",
    "        channels_mask &= (channel_names != channel)\n",
    "    nozeros_mask = np.sum(eeg_data[:, :sampling_rate * 2], 1) != 0\n",
    "    without_emp_mask = nozeros_mask & channels_mask\n",
    "    \n",
    "    # Remove constant (zero) channels and prespecified channels\n",
    "    eeg_data = eeg_data[without_emp_mask, :]\n",
    "\n",
    "    return eeg_data, without_emp_mask\n",
    "    \n",
    "\n",
    "def extract_features(eeg_data, states_labels, states_codes, sampling_rate):\n",
    "    \"\"\"\n",
    "    Construct features: project eeg data on CSP components (separately for each of specified frequency bands)\n",
    "    \"\"\"\n",
    "    N_CSP_comp = 3 # N first and N last; 2*N in total\n",
    "    window_to_sampling_rate = 2\n",
    "    win = sampling_rate // window_to_sampling_rate # Window for averaging: 0.5 sec\n",
    "    eeg_data, all_CSPs, where_states = const_features(eeg_data,states_labels,states_codes,sampling_rate,'CSP_one_vs_all',\n",
    "                                                        CSP_FREQUENCES,'separately',N_CSP_comp,win)\n",
    "    \n",
    "    return eeg_data[:, sampling_rate:], states_labels[:, sampling_rate:].ravel(), all_CSPs, win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbergetter = re.compile(r\"\\d+$\")\n",
    "def get_tail_number(string):\n",
    "    return int(numbergetter.findall(string)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaselineModel(object):\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def fit(self, eeg, states_labels):\n",
    "        states_codes = list(np.unique(states_labels))\n",
    "        filtered_eeg, self.selected_channels = filter_eeg(\n",
    "            eeg, SAMPLING_RATE, CHANNEL_NAMES, states_codes)\n",
    "\n",
    "        # Remove outliers; remove artefacts (blinks, eye movements)\n",
    "        eye_channel_index = (CHANNEL_NAMES[self.selected_channels] == EYE_CHANNEL)\n",
    "        selected_items = remove_outliers(filtered_eeg, 7)\n",
    "        filtered_eeg, self.M_eog = remove_eog_simple(filtered_eeg, eye_channel_index)\n",
    "\n",
    "        extracted_features, labels, self.all_CSPs, self.averaging_window = extract_features(\n",
    "            filtered_eeg[:, selected_items], states_labels[:, selected_items], states_codes, SAMPLING_RATE)\n",
    "\n",
    "        self.classifier.fit(extracted_features.T, labels)\n",
    "        \n",
    "    def predict_proba(self, eeg):\n",
    "        test_eeg = butter_bandpass_filter(\n",
    "            eeg, 0.5, 45, SAMPLING_RATE, order=5, how_to_filt='separately')[self.selected_channels]\n",
    "        test_eeg = self.M_eog.dot(test_eeg)\n",
    "        test_features = filt_apply_CSPs(\n",
    "            test_eeg, SAMPLING_RATE, CSP_FREQUENCES, self.all_CSPs, 'separately', \n",
    "            self.averaging_window, no_filt_no_csp=False)\n",
    "        return self.classifier.predict_proba(test_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples left after outliers removal: 100390\n",
      "Samples left after outliers removal: 98884\n",
      "Samples left after outliers removal: 95921\n",
      "Samples left after outliers removal: 93717\n",
      "Samples left after outliers removal: 92399\n",
      "Samples left after outliers removal: 91637\n",
      "Samples left after outliers removal: 91217\n",
      "Number of samples identified as containing eye artifacts: 1001\n",
      "Shape of data matrix:  (270, 91217)\n",
      "Subject subject_0; train ROC AUC: 0.995772\n",
      "Samples left after outliers removal: 53104\n",
      "Samples left after outliers removal: 51461\n",
      "Samples left after outliers removal: 50183\n",
      "Samples left after outliers removal: 49349\n",
      "Samples left after outliers removal: 48725\n",
      "Samples left after outliers removal: 48263\n",
      "Samples left after outliers removal: 47933\n",
      "Number of samples identified as containing eye artifacts: 856\n",
      "Shape of data matrix:  (270, 47933)\n",
      "Subject subject_1; train ROC AUC: 0.977660\n",
      "Samples left after outliers removal: 54905\n",
      "Samples left after outliers removal: 54110\n",
      "Samples left after outliers removal: 52485\n",
      "Samples left after outliers removal: 51002\n",
      "Samples left after outliers removal: 49992\n",
      "Samples left after outliers removal: 49364\n",
      "Samples left after outliers removal: 48988\n",
      "Number of samples identified as containing eye artifacts: 929\n",
      "Shape of data matrix:  (270, 48988)\n",
      "Subject subject_2; train ROC AUC: 0.988735\n",
      "Samples left after outliers removal: 100279\n",
      "Samples left after outliers removal: 99330\n",
      "Samples left after outliers removal: 96771\n",
      "Samples left after outliers removal: 94454\n",
      "Samples left after outliers removal: 93038\n",
      "Samples left after outliers removal: 92242\n",
      "Samples left after outliers removal: 91740\n",
      "Number of samples identified as containing eye artifacts: 810\n",
      "Shape of data matrix:  (270, 91740)\n",
      "Subject subject_3; train ROC AUC: 0.998001\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(TRAIN_FILE, 'r') as data_file:\n",
    "    with h5py.File(TEST_FILE, 'r') as test_file:\n",
    "        with open(\"baseline_submission.csv\", \"w\") as submission_io:\n",
    "            answers_writer = csv.writer(submission_io)\n",
    "            answers_writer.writerow(\n",
    "                [\"subject_id\", \"chunk_id\", \"tick\", \"class_0_score\", \"class_1_score\", \"class_2_score\"])\n",
    "            for subject, subject_data in data_file.items():\n",
    "                model = BaselineModel(RandomForestClassifier(n_jobs=-1))\n",
    "                model.fit(subject_data['data'], subject_data['labels'])\n",
    "                # The exercise of setting up the proper cross-validation we leave to the reader\n",
    "                print(\"Subject %s; train ROC AUC: %f\" % (subject, roc_auc_score(LabelBinarizer().fit_transform(\n",
    "                            np.ravel(subject_data['labels'])),\n",
    "                            model.predict_proba(subject_data['data']))))\n",
    "                for chunk_id, chunk in test_file[subject].items():\n",
    "                    chunk_prediction = model.predict_proba(chunk)\n",
    "                    answers_writer.writerows([chain(\n",
    "                            [get_tail_number(subject), get_tail_number(chunk_id), x[0]], x[1])\n",
    "                                              for x in enumerate(chunk_prediction)])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_env]",
   "language": "python",
   "name": "conda-env-py3_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
